# Bayan – BinBaz Fatwa Assistant (Arabic)

Bayan is an Arabic fatwa assistant built on top of the published fatwas of **Shaykh Abdulaziz ibn Baz (رحمه الله)**.

The system:

- Uses the **BinBaz fatwas dataset from Kaggle** for the core Q&A pairs.
- Uses **dense retrieval** (BGE-M3 embeddings) to find the closest fatwas to a user question.
- Uses a **local Arabic LLM (ALLaM)** to rephrase / synthesize answers in clear Modern Standard Arabic.
- Explicitly tells the user whether:
  - an existing BinBaz question is found (exact/near match), or  
  - it is only giving a **best-effort approximate answer** based on related fatwas.

> ⚠️ **Religious disclaimer**  
> This project is for educational and research purposes.  
> It is **not** an official project of Shaykh Ibn Baz, his estate, or any Saudi religious body.  
> The answers are generated by a machine-learning model and **do not replace asking qualified scholars**.

---

## Data Sources

### Official Sheikh Ibn Baz Website

The original Arabic fatwas and texts are published on the official website:

- **Official website:** <https://binbaz.org.sa/>

Please always refer back to the official site for the authoritative fatwa text and full context.

### Kaggle Dataset

This project uses the public Kaggle dataset:

- **Dataset:** [Bin Baz Fatwas Dataset – Kaggle](https://www.kaggle.com/datasets/a5medashraf/bin-baz-fatwas-dataset)

Columns used:

- `questions`
- `answers`
- `titles`
- `links`
- `categories`

The dataset belongs to its original author; check the Kaggle page for licensing and usage terms.

---

## Project Overview

High-level architecture:

1. **Data prep**
   - Load Kaggle CSV.
   - Normalize columns and add IDs.
   - Save a clean `fatwas.parquet` file.

2. **Indexing**
   - Encode question + answer pairs using `BAAI/bge-m3` (via `FlagEmbedding`).
   - Store:
     - `data/index/fatwas_embeddings.npy` (normalized dense vectors),
     - `data/index/fatwas_meta.parquet` (id, question, answer, title, link, categories).

3. **Retrieval**
   - For a new user question:
     - Embed with BGE-M3.
     - Compute cosine similarity against precomputed vectors (pure NumPy).
     - Return top-k fatwas + similarity scores.

4. **LLM answer generation**
   - Load an Arabic instruction model (ALLaM 7B, GGUF) via `llama-cpp-python`.
   - Build a prompt that:
     - Injects the closest fatwas (exact or approximate).
     - Instructs the model to **stick to Ibn Baz’s fatwas only**, not make up new rulings.
   - Generate an Arabic answer and add a safety disclaimer at the end.

5. **Interfaces**
   - **FastAPI backend** (`/api/chat`) for programmatic access.
   - Simple **HTML + JS chat UI** (local).
   - **Gradio app** (used in the Hugging Face Space).

---

## Requirements

- Python **3.10+** (recommended)
- Windows/Linux/macOS
- Optional GPU:
  - Locally you can set `n_gpu_layers` in `llm.py` > 0 to offload some layers to GPU.
  - On CPU-only environments (like most HF Spaces) keep `n_gpu_layers=0`.

Main Python deps (see `requirements.txt`):

- `gradio`
- `fastapi` + `uvicorn`
- `pandas`, `numpy`
- `FlagEmbedding` (BGE-M3 embeddings)
- `llama-cpp-python` (ALLaM 7B, GGUF)

---

## Quickstart – Local Development

### 1. Clone and set up environment

```bash
git clone https://github.com/<YOUR_GITHUB_USERNAME>/Bayan-BinBaz.git
cd Bayan-BinBaz

python -m venv .venv
# Windows
.\.venv\Scripts\activate
# Linux/macOS
# source .venv/bin/activate

pip install -r requirements.txt